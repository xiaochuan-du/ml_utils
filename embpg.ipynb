{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from imp import reload\n",
    "import re\n",
    "import pickle\n",
    "import math, keras, datetime, pandas as pd, numpy as np, keras.backend as K\n",
    "from pandas_summary import DataFrameSummary\n",
    "import bld_etl; reload(bld_etl)\n",
    "from keras.preprocessing import sequence\n",
    "from bld_etl import read_raw, loadtypes, add_datepart, fillna, type_map, get_data\n",
    "from sklearn.model_selection  import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Embedding, Concatenate\n",
    "from keras import initializers, Model\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_fasttest_to_vectors(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        data = f.readlines()\n",
    "    samples, dim = data[0].split()\n",
    "    samples, dim = int(samples), int(dim)\n",
    "    wordidx = {}\n",
    "    vecs = np.zeros((samples, dim), dtype='float32')\n",
    "    for idx, line in enumerate(data[1:]):\n",
    "        word, vec = line.split(' ', 1)\n",
    "        vecs[idx] = np.array([ float(i) for i in vec.split()])\n",
    "        wordidx[word] = idx\n",
    "    return vecs, list(wordidx.keys()), wordidx\n",
    "\n",
    "def dump_vectors(loc, vecs, words, wordidx):\n",
    "    return (bld_etl.save_array(loc+'.dat', vecs),\n",
    "        pickle.dump(words, open(loc+'_words.pkl','wb')),\n",
    "        pickle.dump(wordidx, open(loc+'_idx.pkl','wb')) )\n",
    "\n",
    "\n",
    "def load_vectors(loc):\n",
    "    return (bld_etl.load_array(loc+'.dat'),\n",
    "        pickle.load(open(loc+'_words.pkl','rb')),\n",
    "        pickle.load(open(loc+'_idx.pkl','rb')))\n",
    "# dump_vectors('/root/.keras/models/fsttxtzh300', vecs, words, wordidx)\n",
    "# vecs, words, wordidx = from_fasttest_to_vectors('/root/.keras/models/fsttxtzh300')\n",
    "\n",
    "def create_emb(vocab_size, vecs, words):\n",
    "    words_set = set(words_set)\n",
    "    n_fact = vecs.shape[1]\n",
    "    emb = np.zeros((vocab_size, n_fact))\n",
    "\n",
    "    for i in range(1,len(emb)):\n",
    "        word = idx2word[i]\n",
    "        if re.match(r\"^[A-Z]*$\", word):\n",
    "            word = word.lower()\n",
    "        if word and (word in words_set):\n",
    "            src_idx = wordidx[word]\n",
    "            emb[i] = vecs[src_idx]\n",
    "        else:\n",
    "            # If we can't find the word in glove, randomly initialize\n",
    "            emb[i] = normal(scale=0.6, size=(n_fact,))\n",
    "\n",
    "    # This is our \"rare word\" id - we want to randomly initialize\n",
    "    emb[-1] = normal(scale=0.6, size=(n_fact,))\n",
    "    emb/=3\n",
    "    return emb\n",
    "\n",
    "def par2idx(para, words):\n",
    "    words_set = set(words)\n",
    "    paras = []\n",
    "    for word in para:\n",
    "        if re.match(r\"^[A-Z]*$\", word):\n",
    "            word = word.lower()\n",
    "        if word and (word in words_set):\n",
    "            paras.append(wordidx[word])\n",
    "        else:\n",
    "            paras.append(-1)\n",
    "    return np.array(paras, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs, words, wordidx = load_vectors('/root/.keras/models/fsttxtzh300')\n",
    "idx2word = {v: k for k, v in wordidx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined = pd.read_pickle('/data/result/cleaned_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_df = joined.assign(ishigh=joined.TRANS_RBC > 3.5)[ ['OP_NAME', 'ishigh', 'TRANS_RBC']]\n",
    "data_df.ishigh = data_df.ishigh.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [par2idx(line, words) for line in joined.OP_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 5000 # vocab_size = vecs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn, test, y_train, y_test = train_test_split(corpus, joined.TRANS_RBC.values, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = 80\n",
    "\n",
    "trn = sequence.pad_sequences(trn, maxlen=seq_len, value=0)\n",
    "test = sequence.pad_sequences(test, maxlen=seq_len, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4165, 80)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb = vecs[:vocab_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 5, activation=\"relu\", padding=\"same\")`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, 300, input_length=seq_len, dropout=0.2, \n",
    "              weights=[emb], trainable=False),\n",
    "    Dropout(0.25),\n",
    "    Convolution1D(64, 5, border_mode='same', activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(1, activation='linear')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4165 samples, validate on 1042 samples\n",
      "Epoch 1/20\n",
      "4165/4165 [==============================] - 2s 391us/step - loss: 13.1700 - acc: 0.1885 - val_loss: 7.6949 - val_acc: 0.3100\n",
      "Epoch 2/20\n",
      "4165/4165 [==============================] - 0s 72us/step - loss: 8.0229 - acc: 0.1926 - val_loss: 7.8086 - val_acc: 0.3119\n",
      "Epoch 3/20\n",
      "4165/4165 [==============================] - 0s 66us/step - loss: 7.6613 - acc: 0.2067 - val_loss: 8.5891 - val_acc: 0.3580\n",
      "Epoch 4/20\n",
      "4165/4165 [==============================] - 0s 63us/step - loss: 7.5623 - acc: 0.2024 - val_loss: 8.3645 - val_acc: 0.3369\n",
      "Epoch 5/20\n",
      "4165/4165 [==============================] - 0s 63us/step - loss: 7.6226 - acc: 0.2053 - val_loss: 7.4216 - val_acc: 0.3225\n",
      "Epoch 6/20\n",
      "4165/4165 [==============================] - 0s 62us/step - loss: 7.2710 - acc: 0.2038 - val_loss: 6.2648 - val_acc: 0.1804\n",
      "Epoch 7/20\n",
      "4165/4165 [==============================] - 0s 63us/step - loss: 7.5517 - acc: 0.2108 - val_loss: 6.9188 - val_acc: 0.2620\n",
      "Epoch 8/20\n",
      "4165/4165 [==============================] - 0s 63us/step - loss: 7.3066 - acc: 0.2072 - val_loss: 6.9611 - val_acc: 0.2370\n",
      "Epoch 9/20\n",
      "4165/4165 [==============================] - 0s 65us/step - loss: 7.4279 - acc: 0.2168 - val_loss: 6.9514 - val_acc: 0.2630\n",
      "Epoch 10/20\n",
      "4165/4165 [==============================] - 0s 74us/step - loss: 7.1404 - acc: 0.2067 - val_loss: 6.1863 - val_acc: 0.1804\n",
      "Epoch 11/20\n",
      "4165/4165 [==============================] - 0s 66us/step - loss: 7.3226 - acc: 0.2074 - val_loss: 6.4946 - val_acc: 0.2342\n",
      "Epoch 12/20\n",
      "4165/4165 [==============================] - 0s 67us/step - loss: 6.9710 - acc: 0.2048 - val_loss: 7.3359 - val_acc: 0.2975\n",
      "Epoch 13/20\n",
      "4165/4165 [==============================] - 0s 76us/step - loss: 6.9289 - acc: 0.2046 - val_loss: 7.5911 - val_acc: 0.3330\n",
      "Epoch 14/20\n",
      "4165/4165 [==============================] - 0s 71us/step - loss: 6.8872 - acc: 0.2161 - val_loss: 6.3927 - val_acc: 0.2236\n",
      "Epoch 15/20\n",
      "4165/4165 [==============================] - 0s 64us/step - loss: 6.9282 - acc: 0.2127 - val_loss: 6.6359 - val_acc: 0.2438\n",
      "Epoch 16/20\n",
      "4165/4165 [==============================] - 0s 67us/step - loss: 6.7227 - acc: 0.2194 - val_loss: 6.7751 - val_acc: 0.2687\n",
      "Epoch 17/20\n",
      "4165/4165 [==============================] - 0s 65us/step - loss: 6.7383 - acc: 0.2158 - val_loss: 6.0188 - val_acc: 0.1910\n",
      "Epoch 18/20\n",
      "4165/4165 [==============================] - 0s 65us/step - loss: 6.9246 - acc: 0.2235 - val_loss: 7.5003 - val_acc: 0.3129\n",
      "Epoch 19/20\n",
      "4165/4165 [==============================] - 0s 64us/step - loss: 6.8137 - acc: 0.2185 - val_loss: 7.0258 - val_acc: 0.2908\n",
      "Epoch 20/20\n",
      "4165/4165 [==============================] - 0s 67us/step - loss: 6.6435 - acc: 0.2173 - val_loss: 6.0934 - val_acc: 0.2054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa2c40d0978>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn, y_train, validation_data=(test, y_test), epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4165 samples, validate on 1042 samples\n",
      "Epoch 1/20\n",
      "2112/4165 [==============>...............] - ETA: 0s - loss: 5.4444 - acc: 0.2320"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4165/4165 [==============================] - 0s 77us/step - loss: 5.5140 - acc: 0.2315 - val_loss: 6.2965 - val_acc: 0.2054\n",
      "Epoch 2/20\n",
      "4165/4165 [==============================] - 0s 65us/step - loss: 5.7532 - acc: 0.2238 - val_loss: 6.4225 - val_acc: 0.2111\n",
      "Epoch 3/20\n",
      "4165/4165 [==============================] - 0s 62us/step - loss: 5.5955 - acc: 0.2252 - val_loss: 6.9298 - val_acc: 0.2812\n",
      "Epoch 4/20\n",
      "4165/4165 [==============================] - 0s 59us/step - loss: 5.6416 - acc: 0.2370 - val_loss: 6.5080 - val_acc: 0.2198\n",
      "Epoch 5/20\n",
      "4165/4165 [==============================] - ETA: 0s - loss: 5.3535 - acc: 0.225 - 0s 61us/step - loss: 5.2847 - acc: 0.2276 - val_loss: 6.3902 - val_acc: 0.2111\n",
      "Epoch 6/20\n",
      "4165/4165 [==============================] - 0s 61us/step - loss: 5.4929 - acc: 0.2339 - val_loss: 6.1011 - val_acc: 0.1631\n",
      "Epoch 7/20\n",
      "4165/4165 [==============================] - 0s 57us/step - loss: 5.5326 - acc: 0.2312 - val_loss: 6.4340 - val_acc: 0.2121\n",
      "Epoch 8/20\n",
      "4165/4165 [==============================] - 0s 58us/step - loss: 5.3507 - acc: 0.2427 - val_loss: 6.2306 - val_acc: 0.1795\n",
      "Epoch 9/20\n",
      "4165/4165 [==============================] - 0s 58us/step - loss: 5.1849 - acc: 0.2267 - val_loss: 6.1813 - val_acc: 0.1900\n",
      "Epoch 10/20\n",
      "4165/4165 [==============================] - 0s 59us/step - loss: 5.2084 - acc: 0.2269 - val_loss: 6.1298 - val_acc: 0.1833\n",
      "Epoch 11/20\n",
      "4165/4165 [==============================] - 0s 57us/step - loss: 4.9899 - acc: 0.2360 - val_loss: 6.3353 - val_acc: 0.2025\n",
      "Epoch 12/20\n",
      "4165/4165 [==============================] - 0s 60us/step - loss: 5.0744 - acc: 0.2444 - val_loss: 6.3264 - val_acc: 0.2092\n",
      "Epoch 13/20\n",
      "4165/4165 [==============================] - 0s 57us/step - loss: 4.9316 - acc: 0.2439 - val_loss: 6.8084 - val_acc: 0.2908\n",
      "Epoch 14/20\n",
      "4165/4165 [==============================] - 0s 61us/step - loss: 4.8464 - acc: 0.2538 - val_loss: 6.5581 - val_acc: 0.2418\n",
      "Epoch 15/20\n",
      "4165/4165 [==============================] - 0s 58us/step - loss: 5.1727 - acc: 0.2372 - val_loss: 6.1010 - val_acc: 0.1660\n",
      "Epoch 16/20\n",
      "4165/4165 [==============================] - 0s 56us/step - loss: 5.0211 - acc: 0.2295 - val_loss: 6.3201 - val_acc: 0.1823\n",
      "Epoch 17/20\n",
      "4165/4165 [==============================] - 0s 57us/step - loss: 4.9369 - acc: 0.2331 - val_loss: 6.1249 - val_acc: 0.1881\n",
      "Epoch 18/20\n",
      "4165/4165 [==============================] - 0s 57us/step - loss: 4.8411 - acc: 0.2437 - val_loss: 6.2148 - val_acc: 0.1919\n",
      "Epoch 19/20\n",
      "4165/4165 [==============================] - 0s 58us/step - loss: 4.9893 - acc: 0.2449 - val_loss: 6.2784 - val_acc: 0.2063\n",
      "Epoch 20/20\n",
      "4165/4165 [==============================] - 0s 57us/step - loss: 4.8667 - acc: 0.2468 - val_loss: 5.9361 - val_acc: 0.1679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa2c82543c8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn, y_train, validation_data=(test, y_test), epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7044254c836b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdiff0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1042\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "diff0 = np.array(y_test).reshape(1, 1042)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff1 = np.array(predicted).reshape(1, 1042)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'diff1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-92775c3dbd04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiff1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdiff0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'diff1' is not defined"
     ]
    }
   ],
   "source": [
    "diff = diff1 - diff0\n",
    "diff = diff.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff[diff> 1] = 0\n",
    "diff[diff< -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "601"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(diff == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_axes.py:6097: UserWarning: 2D hist input should be nsamples x nvariables;\n",
      " this looks transposed (shape is 1 x 1042)\n",
      "  '(shape is %d x %d)' % inp.shape[::-1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-d29ff6ce81ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(x, bins, range, normed, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3079\u001b[0m                       \u001b[0mhisttype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhisttype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3080\u001b[0m                       \u001b[0mrwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3081\u001b[0;31m                       stacked=stacked, data=data, **kwargs)\n\u001b[0m\u001b[1;32m   3082\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3083\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1896\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1897\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   6277\u001b[0m                 patch = _barfunc(bins[:-1]+boffset, height, width,\n\u001b[1;32m   6278\u001b[0m                                  \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6279\u001b[0;31m                                  color=c, **{bottom_kwarg: bottom})\n\u001b[0m\u001b[1;32m   6280\u001b[0m                 \u001b[0mpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6281\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstacked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1896\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1897\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, left, height, width, bottom, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m             \u001b[0mymin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mymin\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintervaly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mymin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2171\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoscale_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2173\u001b[0m         \u001b[0mbar_container\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBarContainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrorbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mautoscale_view\u001b[0;34m(self, tight, scalex, scaley)\u001b[0m\n\u001b[1;32m   2266\u001b[0m             \u001b[0mstickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msticky_edges\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0martist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2267\u001b[0m             \u001b[0mx_stickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msticky\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msticky\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstickies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m             \u001b[0my_stickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msticky\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msticky\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstickies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2269\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'log'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m                 \u001b[0mx_stickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_stickies\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mxs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "plt.hist(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4165 samples, validate on 1042 samples\n",
      "Epoch 1/20\n",
      "1984/4165 [=============>................] - ETA: 0s - loss: 0.6572 - acc: 0.5978"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4165/4165 [==============================] - 0s 87us/step - loss: 0.6568 - acc: 0.6005 - val_loss: 0.6567 - val_acc: 0.5893\n",
      "Epoch 2/20\n",
      "4165/4165 [==============================] - 0s 80us/step - loss: 0.6531 - acc: 0.5935 - val_loss: 0.6568 - val_acc: 0.5883\n",
      "Epoch 3/20\n",
      "4165/4165 [==============================] - 0s 74us/step - loss: 0.6521 - acc: 0.6055 - val_loss: 0.6580 - val_acc: 0.5960\n",
      "Epoch 4/20\n",
      "4165/4165 [==============================] - 0s 82us/step - loss: 0.6498 - acc: 0.5990 - val_loss: 0.6540 - val_acc: 0.5950\n",
      "Epoch 5/20\n",
      "4165/4165 [==============================] - 0s 77us/step - loss: 0.6417 - acc: 0.6053 - val_loss: 0.6562 - val_acc: 0.6008\n",
      "Epoch 6/20\n",
      "4165/4165 [==============================] - 0s 91us/step - loss: 0.6480 - acc: 0.6086 - val_loss: 0.6534 - val_acc: 0.6046\n",
      "Epoch 7/20\n",
      "4165/4165 [==============================] - 0s 94us/step - loss: 0.6449 - acc: 0.6084 - val_loss: 0.6546 - val_acc: 0.5912\n",
      "Epoch 8/20\n",
      "4165/4165 [==============================] - 0s 94us/step - loss: 0.6437 - acc: 0.6000 - val_loss: 0.6534 - val_acc: 0.5912\n",
      "Epoch 9/20\n",
      "4165/4165 [==============================] - 0s 82us/step - loss: 0.6405 - acc: 0.6118 - val_loss: 0.6535 - val_acc: 0.6084\n",
      "Epoch 10/20\n",
      "4165/4165 [==============================] - 0s 93us/step - loss: 0.6444 - acc: 0.6079 - val_loss: 0.6531 - val_acc: 0.6084\n",
      "Epoch 11/20\n",
      "4165/4165 [==============================] - 0s 91us/step - loss: 0.6483 - acc: 0.6029 - val_loss: 0.6523 - val_acc: 0.5979\n",
      "Epoch 12/20\n",
      "4165/4165 [==============================] - 0s 95us/step - loss: 0.6417 - acc: 0.6151 - val_loss: 0.6509 - val_acc: 0.5969\n",
      "Epoch 13/20\n",
      "4165/4165 [==============================] - 0s 100us/step - loss: 0.6376 - acc: 0.6192 - val_loss: 0.6525 - val_acc: 0.5912\n",
      "Epoch 14/20\n",
      "4165/4165 [==============================] - 0s 99us/step - loss: 0.6327 - acc: 0.6202 - val_loss: 0.6550 - val_acc: 0.5969\n",
      "Epoch 15/20\n",
      "4165/4165 [==============================] - 0s 90us/step - loss: 0.6369 - acc: 0.6223 - val_loss: 0.6531 - val_acc: 0.5969\n",
      "Epoch 16/20\n",
      "4165/4165 [==============================] - 0s 83us/step - loss: 0.6281 - acc: 0.6262 - val_loss: 0.6590 - val_acc: 0.6046\n",
      "Epoch 17/20\n",
      "4165/4165 [==============================] - 0s 95us/step - loss: 0.6356 - acc: 0.6168 - val_loss: 0.6515 - val_acc: 0.5931\n",
      "Epoch 18/20\n",
      "4165/4165 [==============================] - 0s 84us/step - loss: 0.6329 - acc: 0.6156 - val_loss: 0.6556 - val_acc: 0.6027\n",
      "Epoch 19/20\n",
      "4165/4165 [==============================] - 0s 93us/step - loss: 0.6322 - acc: 0.6156 - val_loss: 0.6493 - val_acc: 0.5969\n",
      "Epoch 20/20\n",
      "4165/4165 [==============================] - 0s 85us/step - loss: 0.6292 - acc: 0.6259 - val_loss: 0.6558 - val_acc: 0.6075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7f9d13c390>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
