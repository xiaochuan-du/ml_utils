{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip3 install pandas_summary isoweek sklearn_pandas -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "! pip3 install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from imp import reload\n",
    "import re\n",
    "import pickle\n",
    "import math, keras, datetime, pandas as pd, numpy as np, keras.backend as K\n",
    "from pandas_summary import DataFrameSummary\n",
    "import bld_etl; reload(bld_etl)\n",
    "from keras.preprocessing import sequence\n",
    "from bld_etl import read_raw, loadtypes, add_datepart, fillna, type_map, get_data\n",
    "from sklearn.model_selection  import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Embedding, Concatenate\n",
    "from keras import initializers, Model\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras import optimizers\n",
    "\n",
    "import math, keras, datetime, pandas as pd, numpy as np, keras.backend as K\n",
    "from pandas_summary import DataFrameSummary\n",
    "import bld_etl; reload(bld_etl)\n",
    "from bld_etl import read_raw, loadtypes, add_datepart, fillna, type_map, get_data, load_vectors, par2idx, load_var, dump_var\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(threshold=50, edgeitems=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs, words, wordidx = load_vectors('/root/.keras/models/fsttxtzh300')\n",
    "idx2word = {v: k for k, v in wordidx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py:2352: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.read_json('/data/ai_opinfo_2017-01_to_2017-10.json', lines=True)\n",
    "# filtered the data without RBC\n",
    "merged_df = merged_df[~merged_df.TRANS_RBC.isnull()]\n",
    "y_df, x_df = read_raw(merged_df)\n",
    "contin_vars, cat_vars, dt_vars, text_vars, const_vars = loadtypes(x_df)\n",
    "# drop the cols with contant value, cause this contribute nothing to predicted results\n",
    "x_df.drop(const_vars, axis=1, inplace=True, errors=\"ignore\")\n",
    "add_datepart(x_df, dt_vars)\n",
    "fillna(x_df, contin_vars, cat_vars)\n",
    "contin_vars.remove('TRANS_RBC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "cat_map_fit, contin_map_fit, contin_cols = type_map(joined, cat_vars, contin_vars, use_cache=False, cache_dir='/data/result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/bld_etl.py:144: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  joined_train.drop('TRANS_RBC', axis=1, inplace=True)\n",
      "/notebooks/bld_etl.py:145: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  joined_valid.drop('TRANS_RBC', axis=1, inplace=True)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_valid, y_valid, cat_map_train, cat_map_valid, contin_map_train, contin_map_valid = get_data(joined, cat_map_fit, contin_map_fit)\n",
    "# cat_map_train: mapped categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmspe(y_pred, targ = y_valid):\n",
    "    pct_var = (targ - y_pred)/targ\n",
    "    return math.sqrt(np.square(pct_var).mean())\n",
    "# def log_max_inv(preds, mx = max_log_y):\n",
    "#     return np.exp(preds * mx)\n",
    "def normalize_inv(preds):\n",
    "    return preds * ystd + ymean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split matrix into num (arr.shape[1]) lists\n",
    "def split_cols(arr): return np.hsplit(arr,arr.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_train = split_cols(cat_map_train) + [contin_map_train]\n",
    "map_valid = split_cols(cat_map_valid) + [contin_map_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cat_preproc(dat, cat_map_fit):\n",
    "    \"cat_preproc\"\n",
    "    return cat_map_fit.transform(dat).astype(np.int64)\n",
    "\n",
    "\n",
    "def contin_preproc(dat, contin_map_fit):\n",
    "    \"contin_preproc\"\n",
    "    return contin_map_fit.transform(dat).astype(np.float32)\n",
    "\n",
    "def get_data(joined, cat_map_fit, contin_map_fit, text_vars, wordidx):\n",
    "    y = joined.TRANS_RBC\n",
    "    joined.drop('TRANS_RBC', axis=1, inplace=True, errors='ignore')\n",
    "    cat_map = cat_preproc(joined, cat_map_fit)\n",
    "    contin_map = contin_preproc(joined, contin_map_fit)\n",
    "    \n",
    "    op_name_map = [par2idx(line, words, wordidx) for line in joined.OP_NAME]\n",
    "    diag_name_map = [par2idx(line, words, wordidx) for line in joined.INHOS_DIAG_NAME]\n",
    "    \n",
    "    seq_len = 80\n",
    "    op_name_map = sequence.pad_sequences(op_name_map, maxlen=seq_len, value=0)\n",
    "    diag_name_map = sequence.pad_sequences(diag_name_map, maxlen=seq_len, value=0)\n",
    "    return cat_map, contin_map, op_name_map, diag_name_map, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "joined = pd.read_pickle('/data/result/cleaned_data.pkl')\n",
    "cat_map, contin_map, op_name_map, diag_name_map, y = get_data(joined, cat_map_fit, contin_map_fit, text_vars, wordidx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_var('/data/result/cat_map.pkl', cat_map)\n",
    "dump_var('/data/result/contin_map.pkl', contin_map)\n",
    "dump_var('/data/result/op_name_map.pkl', op_name_map)\n",
    "dump_var('/data/result/diag_name_map.pkl', diag_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_map = load_var('/data/result/cat_map.pkl')\n",
    "contin_map = load_var('/data/result/contin_map.pkl')\n",
    "op_name_map = load_var('/data/result/op_name_map.pkl')\n",
    "diag_name_map = load_var('/data/result/diag_name_map.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = split_cols(cat_map) + [contin_map] + [op_name_map] + [diag_name_map]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = dataset\n",
    "test = dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = split_cols(cat_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5207,)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
