{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dateutil.parser import parse\n",
    "from datetime import date, timedelta\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, wait\n",
    "import functools  \n",
    "\n",
    "import arrow\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'/Users/kevindu/Documents/workspace/ai/data/RRVF/' # r'E:\\workspace\\ai\\ml_utils\\proj\\RRVF\\data\\\\'\n",
    "\n",
    "def get_data(data_path):\n",
    "    air_reserve = pd.read_csv(data_path + 'air_reserve.csv').rename(columns={'air_store_id':'store_id'})\n",
    "    hpg_reserve = pd.read_csv(data_path + 'hpg_reserve.csv').rename(columns={'hpg_store_id':'store_id'})\n",
    "    air_store = pd.read_csv(data_path + 'air_store_info.csv').rename(columns={'air_store_id':'store_id'})\n",
    "    hpg_store = pd.read_csv(data_path + 'hpg_store_info.csv').rename(columns={'hpg_store_id':'store_id'})\n",
    "    air_visit = pd.read_csv(data_path + 'air_visit_data.csv').rename(columns={'air_store_id':'store_id'})\n",
    "    store_id_map = pd.read_csv(data_path + 'store_id_relation.csv').set_index('hpg_store_id',drop=False)\n",
    "    date_info = pd.read_csv(data_path + 'date_info.csv').rename(columns={'calendar_date': 'visit_date'}).drop('day_of_week',axis=1)\n",
    "    submission = pd.read_csv(data_path + 'sample_submission.csv')\n",
    "\n",
    "    submission['visit_date'] = submission['id'].str[-10:]\n",
    "    submission['store_id'] = submission['id'].str[:-11]\n",
    "    air_reserve['visit_date'] = air_reserve['visit_datetime'].str[:10]\n",
    "    air_reserve['reserve_date'] = air_reserve['reserve_datetime'].str[:10]\n",
    "    air_reserve['dow'] = pd.to_datetime(air_reserve['visit_date']).dt.dayofweek\n",
    "    hpg_reserve['visit_date'] = hpg_reserve['visit_datetime'].str[:10]\n",
    "    hpg_reserve['reserve_date'] = hpg_reserve['reserve_datetime'].str[:10]\n",
    "    hpg_reserve['dow'] = pd.to_datetime(hpg_reserve['visit_date']).dt.dayofweek\n",
    "    air_visit['id'] = air_visit['store_id'] + '_' + air_visit['visit_date']\n",
    "    hpg_reserve['store_id'] = hpg_reserve['store_id'].map(store_id_map['air_store_id']).fillna(hpg_reserve['store_id'])\n",
    "    hpg_store['store_id'] = hpg_store['store_id'].map(store_id_map['air_store_id']).fillna(hpg_store['store_id'])\n",
    "    # consider genre in hpg as air genre\n",
    "    hpg_store.rename(columns={'hpg_genre_name':'air_genre_name','hpg_area_name':'air_area_name'},inplace=True)\n",
    "    data = pd.concat([air_visit, submission]).copy()\n",
    "    data['dow'] = pd.to_datetime(data['visit_date']).dt.dayofweek\n",
    "\n",
    "    # take weekend 5 6 1, as a kind of holiday\n",
    "    # dow is a very important feature\n",
    "    date_info['holiday_flg2'] = pd.to_datetime(date_info['visit_date']).dt.dayofweek\n",
    "    date_info['holiday_flg2'] = ((date_info['holiday_flg2']>4) | (date_info['holiday_flg']==1)).astype(int)\n",
    "\n",
    "    # Split on area name, should also consider the number of competitors within a distance\n",
    "    air_store['air_area_name0'] = air_store['air_area_name'].apply(lambda x: x.split(' ')[0])\n",
    "    lbl = LabelEncoder()\n",
    "    air_store['air_genre_name'] = lbl.fit_transform(air_store['air_genre_name'])\n",
    "    air_store['air_area_name0'] = lbl.fit_transform(air_store['air_area_name0'])\n",
    "\n",
    "    # per the chanllege request\n",
    "    data['visitors'] = np.log1p(data['visitors'])\n",
    "    data = data.merge(air_store,on='store_id',how='left')\n",
    "    data = data.merge(date_info[['visit_date','holiday_flg','holiday_flg2']], on=['visit_date'],how='left')\n",
    "    result = {\n",
    "        \"data\": data,\n",
    "        \"hpg_store\": hpg_store,\n",
    "        \"air_store\": air_store,\n",
    "        \"air_reserve\": air_reserve,\n",
    "        \"hpg_reserve\": hpg_reserve,\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(L):\n",
    "    result = None\n",
    "    for l in L:\n",
    "        if result is None:\n",
    "            result = l\n",
    "        else:\n",
    "            try:\n",
    "                result[l.columns.tolist()] = l\n",
    "            except:\n",
    "                print(l.head())\n",
    "    return result\n",
    "\n",
    "def left_merge(data1,data2,on):\n",
    "    if type(on) != list:\n",
    "        on = [on]\n",
    "    if (set(on) & set(data2.columns)) != set(on):\n",
    "        data2_temp = data2.reset_index()\n",
    "    else:\n",
    "        data2_temp = data2.copy()\n",
    "    columns = [f for f in data2.columns if f not in on]\n",
    "    result = data1.merge(data2_temp,on=on,how='left')\n",
    "    result = result[columns]\n",
    "    return result\n",
    "\n",
    "\n",
    "def diff_of_days(day1, day2):\n",
    "    days = (parse(day1[:10]) - parse(day2[:10])).days\n",
    "    return days\n",
    "\n",
    "def date_add_days(start_date, days):\n",
    "    end_date = parse(start_date[:10]) + timedelta(days=days)\n",
    "    end_date = end_date.strftime('%Y-%m-%d')\n",
    "    return end_date\n",
    "\n",
    "def get_label(end_date, n_day):\n",
    "    \"\"\" \n",
    "    end_date : end of statistic set\n",
    "    n_day: the span of label set\n",
    "    \"\"\"\n",
    "    label_end_date = date_add_days(end_date, n_day)\n",
    "    label = data[(data['visit_date'] < label_end_date) & (data['visit_date'] >= end_date)].copy()\n",
    "    label['end_date'] = end_date\n",
    "    # diff of pivot date and visit date\n",
    "    # related to weighting\n",
    "    label['diff_of_day'] = label['visit_date'].apply(lambda x: diff_of_days(x,end_date))\n",
    "    label['month'] = label['visit_date'].str[5:7].astype(int)\n",
    "    label['year'] = label['visit_date'].str[:4].astype(int)\n",
    "    # before & after holiday trend\n",
    "    for i in [3,2,1,-1]:\n",
    "        date_info_temp = date_info.copy()\n",
    "        date_info_temp['visit_date'] = date_info_temp['visit_date'].apply(lambda x: date_add_days(x,i))\n",
    "        date_info_temp.rename(columns={'holiday_flg':'ahead_holiday_{}'.format(i),'holiday_flg2':'ahead_holiday2_{}'.format(i)},inplace=True)\n",
    "        label = label.merge(date_info_temp, on=['visit_date'],how='left')\n",
    "    label = label.reset_index(drop=True)\n",
    "    return label\n",
    "\n",
    "def get_store_visitor_feat(label, key, n_day):\n",
    "    start_date = date_add_days(key[0],-n_day)\n",
    "    data_temp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    result = data_temp.groupby(['store_id'], as_index=False)['visitors'].agg({'store_min{}'.format(n_day): 'min',\n",
    "                                                                             'store_mean{}'.format(n_day): 'mean',\n",
    "                                                                             'store_median{}'.format(n_day): 'median',\n",
    "                                                                             'store_max{}'.format(n_day): 'max',\n",
    "                                                                             'store_count{}'.format(n_day): 'count',\n",
    "                                                                             'store_std{}'.format(n_day): 'std',\n",
    "                                                                             'store_skew{}'.format(n_day): 'skew'})\n",
    "    result = left_merge(label, result, on=['store_id']).fillna(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feats(data_dict, \n",
    "                win,\n",
    "                label_getter, \n",
    "                fes=[], \n",
    "                high_eng=None):\n",
    "        pivot_date = win['pivot_date']\n",
    "        days_in_label = win['days_in_label']\n",
    "        key = pivot_date, days_in_label # the idx of label set\n",
    "        label = label_getter(pivot_date, days_in_label)\n",
    "\n",
    "        result = [label]\n",
    "        for feature_eng in fes:\n",
    "            result.append(feature_eng(label, key))\n",
    "        result.append(label)\n",
    "        result = concat(result)\n",
    "        if high_eng:\n",
    "            result = high_eng(result)\n",
    "        return result\n",
    "\n",
    "class TimeseriesDataset():\n",
    "    def __init__(\n",
    "            self,\n",
    "            pivot_date,\n",
    "            end_date,\n",
    "            data_dict,\n",
    "            date_col,\n",
    "            date_step,\n",
    "            days_in_label,\n",
    "            min_num_in_stat_set,\n",
    "            label_getter, \n",
    "            fes=[], \n",
    "            high_eng=None\n",
    "            ):\n",
    "        self.__pivot_date = pivot_date\n",
    "        self.__data_dict = data_dict\n",
    "        self.__date_col = date_col\n",
    "        self.__end_date = end_date\n",
    "        self.__date_step = date_step\n",
    "        self.__days_in_label = days_in_label\n",
    "        merged_data = data_dict['data']\n",
    "        windows = []\n",
    "        max_date = arrow.get(pivot_date)\n",
    "        min_date = arrow.get(merged_data.visit_date.min())\n",
    "        delta = (max_date - min_date).days - min_num_in_stat_set\n",
    "        nwindows_bf_pivot = int((delta ) / date_step )\n",
    "        nwindows_af_pivot = math.floor((arrow.get(end_date) - arrow.get(pivot_date)).days / date_step)\n",
    "        \n",
    "        start_date = min_date.shift(days=min_num_in_stat_set)\n",
    "        for day_delta in range(nwindows_bf_pivot):\n",
    "            # >= start & < end\n",
    "            windows.append(\n",
    "                {\n",
    "                    \"pivot_date\": start_date.format('YYYY-MM-DD'),\n",
    "                    \"days_in_label\": days_in_label\n",
    "                }\n",
    "            )\n",
    "            start_date = start_date.shift(days=date_step)\n",
    "        start_date = max_date.shift(days=date_step)\n",
    "        ndays_unit_af_pivot = days_in_label  - days_in_label % date_step\n",
    "        for day_delta in range(nwindows_af_pivot):\n",
    "            adaptive_len = ndays_unit_af_pivot - ( day_delta * date_step )\n",
    "            windows.append(\n",
    "                {\n",
    "                    \"pivot_date\": start_date.format('YYYY-MM-DD'),\n",
    "                    \"days_in_label\": adaptive_len\n",
    "                }\n",
    "            )\n",
    "            start_date = start_date.shift(days=date_step)\n",
    "        self.__windows = windows\n",
    "        print('nwindows_bf_pivot:{}, nwindows_af_pivot {}'\n",
    "              .format(nwindows_bf_pivot, nwindows_af_pivot))\n",
    "        print('First window {}'.format(windows[0]))\n",
    "        print('Last window {}'.format(windows[-1]))\n",
    "        self.__label_getter = label_getter\n",
    "        self.__fes= fes\n",
    "        self.__high_eng = high_eng\n",
    "\n",
    "        \n",
    "    def get_trn(self, concurrency=2):\n",
    "        feats, results = [], []\n",
    "        step_task = int(len(self.__windows) / 100)\n",
    "        num_tasks = len(self.__windows)        \n",
    "        with ThreadPoolExecutor(max_workers=concurrency) as executor:\n",
    "            feats = executor.map(\n",
    "                lambda x: make_feats(win=x,\n",
    "                                    data_dict=self.__data_dict,\n",
    "                                      label_getter=self.__label_getter,\n",
    "                                      fes=self.__fes, \n",
    "                                      high_eng=self.__high_eng), \n",
    "                self.__windows)\n",
    "        train_feat = pd.concat(feats)\n",
    "        return train_feat\n",
    "\n",
    "    def get_test(self, start_date, ndays):\n",
    "        feats = []\n",
    "        test_feat = self.make_feats(pivot_date=start_date, ndays=ndays)\n",
    "        return test_feat\n",
    "\n",
    "    def generate_trn(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = get_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nwindows_bf_pivot:4, nwindows_af_pivot 5\n",
      "First window {'pivot_date': '2016-02-07', 'days_in_label': 39}\n",
      "Last window {'pivot_date': '2016-04-16', 'days_in_label': 7}\n"
     ]
    }
   ],
   "source": [
    "fes= [\n",
    "    lambda label, key: get_store_visitor_feat(label, key, 1000),\n",
    "    lambda label, key: get_store_visitor_feat(label, key, 56)\n",
    "]\n",
    "\n",
    "ts_data = TimeseriesDataset(\n",
    "    pivot_date='2016-03-12',\n",
    "    end_date='2016-04-22',\n",
    "    data_dict=data_dict,\n",
    "    date_col='visit_date',\n",
    "    date_step=7,\n",
    "    days_in_label=39,\n",
    "    min_num_in_stat_set=37,\n",
    "    label_getter=get_label, \n",
    "    fes=fes, \n",
    "    high_eng=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = ts_data.get_trn(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>dow</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>air_area_name0</th>\n",
       "      <th>...</th>\n",
       "      <th>store_count1000</th>\n",
       "      <th>store_std1000</th>\n",
       "      <th>store_skew1000</th>\n",
       "      <th>store_min56</th>\n",
       "      <th>store_mean56</th>\n",
       "      <th>store_median56</th>\n",
       "      <th>store_max56</th>\n",
       "      <th>store_count56</th>\n",
       "      <th>store_std56</th>\n",
       "      <th>store_skew56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24_2016-02-08</td>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-02-08</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.505541</td>\n",
       "      <td>-0.752183</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>2.978754</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.505541</td>\n",
       "      <td>-0.752183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24_2016-02-09</td>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-02-09</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.505541</td>\n",
       "      <td>-0.752183</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>2.978754</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.505541</td>\n",
       "      <td>-0.752183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24_2016-02-10</td>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-02-10</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.505541</td>\n",
       "      <td>-0.752183</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>2.978754</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.505541</td>\n",
       "      <td>-0.752183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24_2016-02-11</td>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-02-11</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.505541</td>\n",
       "      <td>-0.752183</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>2.978754</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.505541</td>\n",
       "      <td>-0.752183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24_2016-02-12</td>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-02-12</td>\n",
       "      <td>3.295837</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.505541</td>\n",
       "      <td>-0.752183</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>2.978754</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.505541</td>\n",
       "      <td>-0.752183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id              store_id  visit_date  \\\n",
       "0  air_ba937bf13d40fb24_2016-02-08  air_ba937bf13d40fb24  2016-02-08   \n",
       "1  air_ba937bf13d40fb24_2016-02-09  air_ba937bf13d40fb24  2016-02-09   \n",
       "2  air_ba937bf13d40fb24_2016-02-10  air_ba937bf13d40fb24  2016-02-10   \n",
       "3  air_ba937bf13d40fb24_2016-02-11  air_ba937bf13d40fb24  2016-02-11   \n",
       "4  air_ba937bf13d40fb24_2016-02-12  air_ba937bf13d40fb24  2016-02-12   \n",
       "\n",
       "   visitors  dow  air_genre_name                 air_area_name   latitude  \\\n",
       "0  2.995732    0               4  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "1  2.772589    1               4  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "2  3.496508    2               4  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "3  1.386294    3               4  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "4  3.295837    4               4  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "\n",
       "    longitude  air_area_name0      ...       store_count1000  store_std1000  \\\n",
       "0  139.751599               7      ...                  20.0       0.505541   \n",
       "1  139.751599               7      ...                  20.0       0.505541   \n",
       "2  139.751599               7      ...                  20.0       0.505541   \n",
       "3  139.751599               7      ...                  20.0       0.505541   \n",
       "4  139.751599               7      ...                  20.0       0.505541   \n",
       "\n",
       "  store_skew1000  store_min56  store_mean56  store_median56  store_max56  \\\n",
       "0      -0.752183      1.94591      2.978754        3.091042     3.828641   \n",
       "1      -0.752183      1.94591      2.978754        3.091042     3.828641   \n",
       "2      -0.752183      1.94591      2.978754        3.091042     3.828641   \n",
       "3      -0.752183      1.94591      2.978754        3.091042     3.828641   \n",
       "4      -0.752183      1.94591      2.978754        3.091042     3.828641   \n",
       "\n",
       "   store_count56  store_std56  store_skew56  \n",
       "0           20.0     0.505541     -0.752183  \n",
       "1           20.0     0.505541     -0.752183  \n",
       "2           20.0     0.505541     -0.752183  \n",
       "3           20.0     0.505541     -0.752183  \n",
       "4           20.0     0.505541     -0.752183  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'store_id', 'visit_date', 'visitors', 'dow', 'air_genre_name',\n",
       "       'air_area_name', 'latitude', 'longitude', 'air_area_name0',\n",
       "       'holiday_flg', 'holiday_flg2', 'end_date', 'diff_of_day', 'month',\n",
       "       'year', 'ahead_holiday_3', 'ahead_holiday2_3', 'ahead_holiday_2',\n",
       "       'ahead_holiday2_2', 'ahead_holiday_1', 'ahead_holiday2_1',\n",
       "       'ahead_holiday_-1', 'ahead_holiday2_-1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
